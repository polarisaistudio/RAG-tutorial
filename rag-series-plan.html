import { useState } from "react";

const PHASES = [
  {
    num: 1, color: "#6366f1", label: "PHASE 1",
    en: { title: "Foundation â€” Core Concepts", sub: "3 videos Â· Concepts" },
    cn: { title: "åŸºç¡€æ¦‚å¿µ", sub: "3 é›† Â· æ¦‚å¿µè®²è§£" },
    videos: [
      {
        id: "01", time: "12-15 min", tags: ["concept"],
        en: {
          title: "What is RAG? The Big Picture",
          outline: [
            "Why LLMs hallucinate and the knowledge cutoff problem",
            "RAG = Retrieval + Augmented + Generation â€” what each word means",
            "The 3-stage pipeline: Indexing â†’ Retrieval â†’ Generation",
            "Real-world use cases: customer support, legal docs, code assistants",
            "RAG vs Fine-tuning vs Prompt Engineering: when to use which",
            "Quick demo: asking ChatGPT without context vs with RAG"
          ],
          desc: `ğŸ” What is RAG (Retrieval-Augmented Generation)? In this video, I explain the big picture of RAG â€” why LLMs hallucinate, how RAG solves this by grounding responses in real data, and when you should use RAG vs fine-tuning vs prompt engineering. Perfect for beginners!

ğŸ“Œ Chapters: 0:00 Intro | 1:30 Why LLMs Hallucinate | 4:00 RAG Pipeline | 8:00 RAG vs Fine-tuning | 11:00 Use Cases
ğŸ”— Blog: https://ml-interview-prep-mu.vercel.app/topics/rag-retrieval`,
          keywords: ["RAG", "retrieval augmented generation", "LLM hallucination", "AI engineering", "RAG tutorial", "RAG vs fine-tuning"],
          visual: "Animated 3-stage RAG pipeline diagram (Indexing â†’ Retrieval â†’ Generation). Side-by-side decision matrix: RAG vs Fine-tuning vs Prompt Engineering."
        },
        cn: {
          title: "ä»€ä¹ˆæ˜¯RAGï¼Ÿå…¨æ™¯æ¦‚è§ˆ",
          outline: [
            "ä¸ºä»€ä¹ˆå¤§æ¨¡å‹ä¼šã€Œå¹»è§‰ã€ï¼ŸçŸ¥è¯†æˆªæ­¢é—®é¢˜",
            "RAG = æ£€ç´¢ + å¢å¼º + ç”Ÿæˆ â€”â€” æ¯ä¸ªè¯çš„å«ä¹‰",
            "ä¸‰é˜¶æ®µç®¡é“ï¼šç´¢å¼• â†’ æ£€ç´¢ â†’ ç”Ÿæˆ",
            "å®é™…åº”ç”¨ï¼šå®¢æœã€æ³•å¾‹æ–‡æ¡£ã€ä»£ç åŠ©æ‰‹",
            "RAG vs å¾®è°ƒ vs æç¤ºå·¥ç¨‹ï¼šå¦‚ä½•é€‰æ‹©",
            "å¿«é€Ÿæ¼”ç¤ºï¼šæ— ä¸Šä¸‹æ–‡ vs æœ‰RAGçš„å›ç­”å¯¹æ¯”"
          ],
          desc: `ğŸ” ä»€ä¹ˆæ˜¯RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ï¼Ÿæœ¬è§†é¢‘å…¨é¢è®²è§£RAGçš„æ ¸å¿ƒåŸç†â€”â€”ä¸ºä»€ä¹ˆå¤§æ¨¡å‹ä¼šã€Œå¹»è§‰ã€ï¼ŒRAGå¦‚ä½•é€šè¿‡æ£€ç´¢çœŸå®æ•°æ®æ¥çº æ­£å›ç­”ï¼Œä»¥åŠRAG vs å¾®è°ƒ vs æç¤ºå·¥ç¨‹è¯¥å¦‚ä½•é€‰æ‹©ã€‚AIå·¥ç¨‹å¸ˆå¿…å¤‡çŸ¥è¯†ï¼

ğŸ“Œ ç« èŠ‚ï¼š0:00 å¼€åœº | 1:30 å¤§æ¨¡å‹ä¸ºä»€ä¹ˆå¹»è§‰ | 4:00 RAGç®¡é“è¯¦è§£ | 8:00 RAG vs å¾®è°ƒ | 11:00 å®é™…åº”ç”¨
ğŸ”— åšå®¢ï¼šhttps://ml-interview-prep-mu.vercel.app/topics/rag-retrieval`,
          keywords: ["RAG", "æ£€ç´¢å¢å¼ºç”Ÿæˆ", "å¤§æ¨¡å‹å¹»è§‰", "AIå·¥ç¨‹å¸ˆ", "RAGæ•™ç¨‹", "RAG vs å¾®è°ƒ"],
          visual: "RAGä¸‰é˜¶æ®µç®¡é“åŠ¨ç”»å›¾ï¼ˆç´¢å¼•â†’æ£€ç´¢â†’ç”Ÿæˆï¼‰ã€‚RAG vs å¾®è°ƒ vs æç¤ºå·¥ç¨‹å¯¹æ¯”å†³ç­–çŸ©é˜µã€‚"
        }
      },
      {
        id: "02", time: "12-15 min", tags: ["concept"],
        en: {
          title: "Embeddings & Vector Similarity Explained",
          outline: ["What are embeddings? From words to high-dimensional vectors", "How embedding models work (sentence-transformers, OpenAI, Cohere)", "Vector similarity: cosine similarity, dot product, Euclidean distance", "Visual intuition: 2D/3D projections of semantic space", "Why \"king - man + woman â‰ˆ queen\" works", "Choosing the right embedding model for your use case"],
          desc: `ğŸ§  How do machines understand meaning? This video breaks down embeddings and vector similarity â€” the core tech powering RAG. Learn cosine similarity, see 3D visualizations, and choose the right embedding model.

ğŸ“Œ Chapters: 0:00 Intro | 2:00 What Are Embeddings | 5:00 Similarity Metrics | 8:00 Visual Demo | 11:00 Choosing Models`,
          keywords: ["embeddings", "vector similarity", "cosine similarity", "sentence transformers", "OpenAI embeddings", "semantic search"],
          visual: "Interactive 3D scatter plot of word embeddings. Animated cosine similarity calculation. Embedding model comparison table."
        },
        cn: {
          title: "Embeddingå‘é‡ä¸ç›¸ä¼¼åº¦æœç´¢è¯¦è§£",
          outline: ["ä»€ä¹ˆæ˜¯Embeddingï¼Ÿä»æ–‡å­—åˆ°é«˜ç»´å‘é‡", "Embeddingæ¨¡å‹åŸç†ï¼ˆsentence-transformersã€OpenAIã€Cohereï¼‰", "å‘é‡ç›¸ä¼¼åº¦ï¼šä½™å¼¦ç›¸ä¼¼åº¦ã€ç‚¹ç§¯ã€æ¬§æ°è·ç¦»", "ç›´è§‰ç†è§£ï¼šè¯­ä¹‰ç©ºé—´çš„2D/3Då¯è§†åŒ–", "ä¸ºä»€ä¹ˆ \"å›½ç‹ - ç”·äºº + å¥³äºº â‰ˆ å¥³ç‹\" æˆç«‹", "å¦‚ä½•ä¸ºä½ çš„åœºæ™¯é€‰æ‹©åˆé€‚çš„Embeddingæ¨¡å‹"],
          desc: `ğŸ§  æœºå™¨å¦‚ä½•ç†è§£è¯­ä¹‰ï¼Ÿæœ¬è§†é¢‘è¯¦è§£Embeddingå‘é‡å’Œç›¸ä¼¼åº¦æœç´¢çš„æ ¸å¿ƒåŸç†ï¼ŒåŒ…æ‹¬ä½™å¼¦ç›¸ä¼¼åº¦ã€æ¬§æ°è·ç¦»ï¼Œä»¥åŠå¦‚ä½•é€‰æ‹©åˆé€‚çš„embeddingæ¨¡å‹ã€‚

ğŸ“Œ ç« èŠ‚ï¼š0:00 å¼€åœº | 2:00 ä»€ä¹ˆæ˜¯Embedding | 5:00 ç›¸ä¼¼åº¦æŒ‡æ ‡ | 8:00 å¯è§†åŒ–æ¼”ç¤º | 11:00 æ¨¡å‹é€‰æ‹©`,
          keywords: ["Embedding", "å‘é‡æœç´¢", "ä½™å¼¦ç›¸ä¼¼åº¦", "sentence-transformers", "è¯­ä¹‰æœç´¢", "embeddingæ¨¡å‹"],
          visual: "è¯­ä¹‰ç©ºé—´3Dæ•£ç‚¹å›¾ã€‚ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—åŠ¨ç”»ã€‚Embeddingæ¨¡å‹å¯¹æ¯”è¡¨ï¼ˆç»´åº¦ã€é€Ÿåº¦ã€è´¹ç”¨ï¼‰ã€‚"
        }
      },
      {
        id: "03", time: "12-15 min", tags: ["concept"],
        en: {
          title: "Chunking Strategies & Vector Databases",
          outline: ["Why chunking matters: too big = noise, too small = lost context", "Strategies: fixed-size, sentence, recursive, semantic chunking", "Overlap and sliding windows", "Vector databases: Pinecone, ChromaDB, Weaviate, pgvector", "Indexing algorithms: HNSW, IVF, brute force", "Metadata filtering and hybrid search preview"],
          desc: `ğŸ“„ How do you split documents for RAG? Covers all chunking strategies and introduces vector databases. Learn HNSW indexing and when to use which.

ğŸ“Œ Chapters: 0:00 Intro | 1:30 Why Chunking Matters | 4:00 Strategies | 8:00 Vector Databases | 11:00 Indexing Algorithms`,
          keywords: ["chunking strategies", "vector database", "Pinecone", "ChromaDB", "Weaviate", "HNSW", "text splitting"],
          visual: "Animated document split with strategies side-by-side. HNSW graph visualization. Vector DB comparison table."
        },
        cn: {
          title: "æ–‡æ¡£åˆ‡åˆ†ç­–ç•¥ä¸å‘é‡æ•°æ®åº“",
          outline: ["ä¸ºä»€ä¹ˆåˆ‡åˆ†å¾ˆé‡è¦ï¼šå¤ªå¤§=å™ªå£°ï¼Œå¤ªå°=ä¸¢å¤±ä¸Šä¸‹æ–‡", "ç­–ç•¥ï¼šå›ºå®šå¤§å°ã€å¥å­çº§ã€é€’å½’ã€è¯­ä¹‰åˆ‡åˆ†", "é‡å å’Œæ»‘åŠ¨çª—å£", "å‘é‡æ•°æ®åº“ï¼šPineconeã€ChromaDBã€Weaviateã€pgvector", "ç´¢å¼•ç®—æ³•ï¼šHNSWã€IVFã€æš´åŠ›æœç´¢", "å…ƒæ•°æ®è¿‡æ»¤å’Œæ··åˆæœç´¢é¢„å‘Š"],
          desc: `ğŸ“„ RAGç³»ç»Ÿä¸­å¦‚ä½•åˆ‡åˆ†æ–‡æ¡£ï¼Ÿè®²è§£å›ºå®šå¤§å°ã€é€’å½’ã€è¯­ä¹‰åˆ‡åˆ†ç­‰ç­–ç•¥ï¼Œä»‹ç»ä¸»æµå‘é‡æ•°æ®åº“å’ŒHNSWç´¢å¼•ç®—æ³•ã€‚

ğŸ“Œ ç« èŠ‚ï¼š0:00 å¼€åœº | 1:30 ä¸ºä»€ä¹ˆåˆ‡åˆ†é‡è¦ | 4:00 åˆ‡åˆ†ç­–ç•¥ | 8:00 å‘é‡æ•°æ®åº“ | 11:00 ç´¢å¼•ç®—æ³•`,
          keywords: ["æ–‡æ¡£åˆ‡åˆ†", "å‘é‡æ•°æ®åº“", "Pinecone", "ChromaDB", "HNSWç®—æ³•", "æ–‡æœ¬åˆ†å‰²"],
          visual: "ä¸åŒåˆ‡åˆ†ç­–ç•¥å¹¶æ’åŠ¨ç”»ã€‚HNSWå›¾å¯è§†åŒ–ã€‚å‘é‡æ•°æ®åº“åŠŸèƒ½/ä»·æ ¼å¯¹æ¯”è¡¨ã€‚"
        }
      }
    ]
  },
  {
    num: 2, color: "#34d399", label: "PHASE 2",
    en: { title: "Hands-On Build â€” Project #1", sub: "4 videos Â· Coding" },
    cn: { title: "åŠ¨æ‰‹å®æˆ˜ â€” é¡¹ç›®ä¸€", sub: "4 é›† Â· ä»£ç å®æˆ˜" },
    videos: [
      {
        id: "04", time: "18-22 min", tags: ["project", "coding"],
        en: {
          title: "Build RAG from Scratch (Part 1): Ingestion Pipeline",
          outline: ["Project overview: Q&A chatbot over your own PDFs", "Setup: Python env, LangChain, OpenAI API key", "Loading documents: PDF, Markdown, web pages", "Implementing recursive text splitter with overlap", "Generating embeddings with OpenAI / free HuggingFace", "Storing in ChromaDB (local, free)", "Testing: verify chunks and search results"],
          desc: `ğŸ› ï¸ Build a RAG system from scratch! Part 1: complete ingestion pipeline â€” loading PDFs, chunking with LangChain, generating embeddings, storing in ChromaDB. Free stack!

ğŸ“Œ Chapters: 0:00 Overview | 2:00 Setup | 5:00 Loading | 9:00 Chunking | 13:00 Embeddings | 17:00 Storage
ğŸ’» GitHub: [repo link]`,
          keywords: ["RAG tutorial python", "LangChain RAG", "ChromaDB tutorial", "build RAG system", "PDF chatbot", "document ingestion"],
          visual: "Ingestion pipeline architecture diagram. Terminal code walkthrough. Before/after: raw doc vs chunked output."
        },
        cn: {
          title: "ä»é›¶æ„å»ºRAGç³»ç»Ÿï¼ˆä¸Šï¼‰ï¼šæ•°æ®æ‘„å–ç®¡é“",
          outline: ["é¡¹ç›®æ¦‚è§ˆï¼šåŸºäºä½ è‡ªå·±PDFæ–‡æ¡£çš„é—®ç­”æœºå™¨äºº", "ç¯å¢ƒæ­å»ºï¼šPythonã€LangChainã€OpenAI API", "åŠ è½½æ–‡æ¡£ï¼šPDFã€Markdownã€ç½‘é¡µ", "å®ç°é€’å½’æ–‡æœ¬åˆ‡åˆ†å™¨ï¼ˆå¸¦é‡å ï¼‰", "ç”ŸæˆEmbeddingï¼šOpenAI / å…è´¹HuggingFace", "å­˜å…¥ChromaDBï¼ˆæœ¬åœ°ã€å…è´¹ï¼‰", "æµ‹è¯•ï¼šéªŒè¯åˆ‡åˆ†å’Œæœç´¢ç»“æœ"],
          desc: `ğŸ› ï¸ ä»é›¶æ„å»ºRAGç³»ç»Ÿï¼ç¬¬ä¸€éƒ¨åˆ†ï¼šå®Œæ•´æ•°æ®æ‘„å–ç®¡é“â€”â€”åŠ è½½PDFã€LangChainåˆ‡åˆ†ã€ç”Ÿæˆå‘é‡ã€å­˜å…¥ChromaDBã€‚å…¨éƒ¨å…è´¹ï¼

ğŸ“Œ ç« èŠ‚ï¼š0:00 é¡¹ç›®æ¦‚è§ˆ | 2:00 ç¯å¢ƒæ­å»º | 5:00 æ–‡æ¡£åŠ è½½ | 9:00 åˆ‡åˆ†ä»£ç  | 13:00 Embedding | 17:00 å­˜å‚¨
ğŸ’» GitHub: [repo link]`,
          keywords: ["RAGå®æˆ˜Python", "LangChainæ•™ç¨‹", "ChromaDBæ•™ç¨‹", "æ„å»ºRAGç³»ç»Ÿ", "PDFèŠå¤©æœºå™¨äºº"],
          visual: "æ‘„å–ç®¡é“æ¶æ„å›¾ã€‚ç»ˆç«¯ä»£ç æ¼”ç¤ºã€‚å‰åå¯¹æ¯”ï¼šåŸå§‹æ–‡æ¡£ vs åˆ‡åˆ†+å‘é‡åŒ–è¾“å‡ºã€‚"
        }
      },
      {
        id: "05", time: "18-22 min", tags: ["project", "coding"],
        en: {
          title: "Build RAG from Scratch (Part 2): Retrieval & Generation",
          outline: ["Building retrieval chain: query â†’ embed â†’ search â†’ rank", "Prompt engineering for RAG: system prompt + context injection", "Connecting to LLM (GPT-4 / free Ollama)", "Building Streamlit chat UI", "Testing with real questions", "Handling edge cases: no docs found, conflicting info"],
          desc: `ğŸ¤– Part 2: Complete the RAG system! Retrieval chain, RAG prompts, LLM integration, Streamlit chat UI. Live demo!

ğŸ“Œ Chapters: 0:00 Recap | 1:30 Retrieval Chain | 6:00 Prompt Design | 10:00 LLM | 14:00 Chat UI | 18:00 Demo
ğŸ’» GitHub: [repo link]`,
          keywords: ["RAG retrieval chain", "LangChain QA", "Streamlit chatbot", "RAG prompt engineering", "Ollama RAG"],
          visual: "Live chatbot demo. Animated flow: query â†’ embedding â†’ search â†’ context â†’ LLM. Split-screen: code + app."
        },
        cn: {
          title: "ä»é›¶æ„å»ºRAGç³»ç»Ÿï¼ˆä¸‹ï¼‰ï¼šæ£€ç´¢ä¸ç”Ÿæˆ",
          outline: ["æ„å»ºæ£€ç´¢é“¾ï¼šæŸ¥è¯¢â†’å‘é‡åŒ–â†’æœç´¢â†’æ’åº", "RAGæç¤ºè¯å·¥ç¨‹ï¼šç³»ç»Ÿæç¤ºè¯+ä¸Šä¸‹æ–‡æ³¨å…¥", "æ¥å…¥å¤§æ¨¡å‹ï¼ˆGPT-4 / å…è´¹Ollamaï¼‰", "StreamlitèŠå¤©ç•Œé¢", "çœŸå®é—®é¢˜æµ‹è¯•", "è¾¹ç•Œæƒ…å†µï¼šæ‰¾ä¸åˆ°æ–‡æ¡£ã€ä¿¡æ¯å†²çª"],
          desc: `ğŸ¤– ç¬¬äºŒéƒ¨åˆ†ï¼šå®ŒæˆRAGç³»ç»Ÿï¼æ£€ç´¢é“¾ã€æç¤ºè¯è®¾è®¡ã€å¤§æ¨¡å‹æ¥å…¥ã€StreamlitèŠå¤©ç•Œé¢ã€‚å®æ—¶æ¼”ç¤ºï¼

ğŸ“Œ ç« èŠ‚ï¼š0:00 å›é¡¾ | 1:30 æ£€ç´¢é“¾ | 6:00 æç¤ºè¯ | 10:00 å¤§æ¨¡å‹ | 14:00 èŠå¤©ç•Œé¢ | 18:00 æ¼”ç¤º
ğŸ’» GitHub: [repo link]`,
          keywords: ["RAGæ£€ç´¢é“¾", "LangChainé—®ç­”", "StreamlitèŠå¤©æœºå™¨äºº", "RAGæç¤ºè¯", "Ollamaæœ¬åœ°éƒ¨ç½²"],
          visual: "èŠå¤©æœºå™¨äººå®æ—¶æ¼”ç¤ºã€‚åŠ¨ç”»æµç¨‹ï¼šæŸ¥è¯¢â†’å‘é‡åŒ–â†’æœç´¢â†’ä¸Šä¸‹æ–‡â†’å¤§æ¨¡å‹ã€‚åˆ†å±ï¼šä»£ç +è¿è¡Œæ•ˆæœã€‚"
        }
      },
      {
        id: "06", time: "15-18 min", tags: ["concept", "coding"],
        en: {
          title: "Hybrid Search: BM25 + Dense Retrieval",
          outline: ["Sparse vs Dense retrieval: when semantic search fails", "BM25 & inverted index explained", "Combining BM25 + vector search", "Reciprocal Rank Fusion (RRF) scoring", "Code: LangChain EnsembleRetriever", "Demo: dense-only vs hybrid results"],
          desc: `ğŸ”€ Why vector search alone isn't enough! Hybrid search with BM25 + dense retrieval + RRF. Hands-on coding demo.

ğŸ“Œ Chapters: 0:00 The Problem | 2:00 BM25 | 6:00 Hybrid Architecture | 10:00 Code | 14:00 Comparison`,
          keywords: ["hybrid search RAG", "BM25", "dense retrieval", "reciprocal rank fusion", "ensemble retriever"],
          visual: "Side-by-side: sparse vs dense on same query. Animated RRF scoring. Accuracy bar chart comparison."
        },
        cn: {
          title: "æ··åˆæœç´¢ï¼šBM25 + ç¨ å¯†æ£€ç´¢",
          outline: ["ç¨€ç–vsç¨ å¯†æ£€ç´¢ï¼šè¯­ä¹‰æœç´¢ä½•æ—¶å¤±æ•ˆ", "BM25ä¸å€’æ’ç´¢å¼•è¯¦è§£", "BM25 + å‘é‡æœç´¢ç»“åˆ", "å€’æ•°æ’åèåˆï¼ˆRRFï¼‰è¯„åˆ†", "ä»£ç ï¼šLangChain EnsembleRetriever", "å¯¹æ¯”ï¼šçº¯ç¨ å¯†vsæ··åˆæœç´¢"],
          desc: `ğŸ”€ ä¸ºä»€ä¹ˆä»…é å‘é‡æœç´¢ä¸å¤Ÿï¼Ÿæ··åˆæœç´¢ï¼šBM25 + ç¨ å¯†æ£€ç´¢ + RRFèåˆã€‚åŒ…å«å®æˆ˜ä»£ç ï¼

ğŸ“Œ ç« èŠ‚ï¼š0:00 é—®é¢˜å¼•å…¥ | 2:00 BM25è¯¦è§£ | 6:00 æ··åˆæ¶æ„ | 10:00 ä»£ç  | 14:00 å¯¹æ¯”`,
          keywords: ["æ··åˆæœç´¢", "BM25ç®—æ³•", "ç¨ å¯†æ£€ç´¢", "å€’æ•°æ’åèåˆ", "EnsembleRetriever"],
          visual: "å¹¶æ’å¯¹æ¯”ï¼šç¨€ç–vsç¨ å¯†æ£€ç´¢ã€‚RRFè¯„åˆ†åŠ¨ç”»ã€‚å‡†ç¡®ç‡æŸ±çŠ¶å›¾å¯¹æ¯”ã€‚"
        }
      },
      {
        id: "07", time: "12-15 min", tags: ["concept", "coding"],
        en: {
          title: "Re-ranking & Two-Stage Retrieval",
          outline: ["Why top-k isn't always accurate", "Two-stage: fast recall â†’ precise re-ranking", "Cross-encoder re-rankers: Cohere, ColBERT, BGE", "Code: adding Cohere Rerank to pipeline", "With vs without re-ranking comparison", "Cost vs quality tradeoff"],
          desc: `ğŸ¯ Level up retrieval with re-ranking! Two-stage architecture + cross-encoder re-rankers. Dramatic quality improvement.

ğŸ“Œ Chapters: 0:00 The Problem | 2:30 Two-Stage | 6:00 Re-rankers | 9:00 Code | 12:00 Results`,
          keywords: ["re-ranking RAG", "cross-encoder", "Cohere rerank", "two-stage retrieval", "ColBERT"],
          visual: "Animated: Stage 1 (recall) â†’ Stage 2 (re-rank). Before/after ranked list. Full enhanced pipeline."
        },
        cn: {
          title: "é‡æ’åºä¸ä¸¤é˜¶æ®µæ£€ç´¢æ¶æ„",
          outline: ["ä¸ºä»€ä¹ˆtop-kä¸å¤Ÿç²¾ç¡®", "ä¸¤é˜¶æ®µï¼šå¿«é€Ÿå¬å›â†’ç²¾ç¡®é‡æ’", "äº¤å‰ç¼–ç å™¨ï¼šCohereã€ColBERTã€BGE", "ä»£ç ï¼šæ·»åŠ Cohereé‡æ’åº", "æœ‰æ— é‡æ’åºæ•ˆæœå¯¹æ¯”", "æˆæœ¬vsè´¨é‡æƒè¡¡"],
          desc: `ğŸ¯ ç”¨é‡æ’åºæå‡æ£€ç´¢è´¨é‡ï¼ä¸¤é˜¶æ®µæ¶æ„+äº¤å‰ç¼–ç å™¨ã€‚å¤§å¹…æå‡å›ç­”è´¨é‡ã€‚

ğŸ“Œ ç« èŠ‚ï¼š0:00 é—®é¢˜ | 2:30 ä¸¤é˜¶æ®µæ¶æ„ | 6:00 é‡æ’æ¨¡å‹ | 9:00 ä»£ç  | 12:00 æ•ˆæœå¯¹æ¯”`,
          keywords: ["é‡æ’åº", "äº¤å‰ç¼–ç å™¨", "Cohere Rerank", "ä¸¤é˜¶æ®µæ£€ç´¢", "ColBERT"],
          visual: "åŠ¨ç”»ï¼šé˜¶æ®µ1ï¼ˆå¬å›ï¼‰â†’é˜¶æ®µ2ï¼ˆé‡æ’ï¼‰ã€‚æ’åå‰åå¯¹æ¯”ã€‚å®Œæ•´å¢å¼ºç®¡é“æ¶æ„å›¾ã€‚"
        }
      }
    ]
  },
  {
    num: 3, color: "#fbbf24", label: "PHASE 3",
    en: { title: "Advanced RAG Techniques", sub: "3 videos Â· Advanced" },
    cn: { title: "è¿›é˜¶æŠ€æœ¯", sub: "3 é›† Â· è¿›é˜¶" },
    videos: [
      {
        id: "08", time: "15-18 min", tags: ["concept", "coding"],
        en: {
          title: "Evaluating RAG: RAGAS, Faithfulness & Relevance",
          outline: ["Why you MUST evaluate (not just vibes)", "Metrics: faithfulness, answer relevance, context precision/recall", "RAGAS framework deep dive", "Code: evaluating with RAGAS", "Building eval datasets: manual + synthetic", "Continuous evaluation in production"],
          desc: `ğŸ“Š How to know if your RAG works? RAGAS framework â€” measure faithfulness, relevance, context quality. Build eval datasets.

ğŸ“Œ Chapters: 0:00 Why Evaluate | 2:00 Metrics | 6:00 RAGAS | 10:00 Code | 14:00 Production`,
          keywords: ["RAG evaluation", "RAGAS", "faithfulness", "answer relevance", "RAG metrics"],
          visual: "Metrics dashboard mockup. Animated evaluation flow. Eval dataset table with ground truth."
        },
        cn: {
          title: "RAGè¯„ä¼°ï¼šRAGASæ¡†æ¶ã€å¿ å®åº¦ä¸ç›¸å…³æ€§",
          outline: ["ä¸ºä»€ä¹ˆå¿…é¡»è¯„ä¼°ï¼ˆä¸èƒ½é æ„Ÿè§‰ï¼‰", "æŒ‡æ ‡ï¼šå¿ å®åº¦ã€å›ç­”ç›¸å…³æ€§ã€ä¸Šä¸‹æ–‡ç²¾ç¡®ç‡/å¬å›ç‡", "RAGASæ¡†æ¶æ·±åº¦è§£æ", "ä»£ç ï¼šç”¨RAGASè¯„ä¼°", "æ„å»ºè¯„ä¼°æ•°æ®é›†ï¼šæ‰‹åŠ¨+è‡ªåŠ¨åˆæˆ", "ç”Ÿäº§ç¯å¢ƒæŒç»­è¯„ä¼°"],
          desc: `ğŸ“Š å¦‚ä½•åˆ¤æ–­RAGå¥½ä¸å¥½ï¼ŸRAGASè¯„ä¼°æ¡†æ¶â€”â€”å¿ å®åº¦ã€ç›¸å…³æ€§ã€ä¸Šä¸‹æ–‡è´¨é‡ã€‚å®æˆ˜æ„å»ºè¯„ä¼°æ•°æ®é›†ã€‚

ğŸ“Œ ç« èŠ‚ï¼š0:00 ä¸ºä»€ä¹ˆè¯„ä¼° | 2:00 æŒ‡æ ‡ | 6:00 RAGAS | 10:00 ä»£ç  | 14:00 ç”Ÿäº§ç›‘æ§`,
          keywords: ["RAGè¯„ä¼°", "RAGASæ¡†æ¶", "å¿ å®åº¦", "å›ç­”ç›¸å…³æ€§", "è¯„ä¼°æŒ‡æ ‡"],
          visual: "è¯„ä¼°ä»ªè¡¨ç›˜ã€‚åŠ¨ç”»è¯„ä¼°æµç¨‹ã€‚è¯„ä¼°æ•°æ®é›†è¡¨æ ¼ã€‚"
        }
      },
      {
        id: "09", time: "15-18 min", tags: ["concept"],
        en: {
          title: "Advanced RAG Patterns: HyDE, Self-RAG, CRAG",
          outline: ["Pre-retrieval: query expansion, decomposition, step-back", "HyDE: Hypothetical Document Embeddings", "Self-RAG: LLM decides when to retrieve", "Post-retrieval: context compression, lost-in-the-middle", "Corrective RAG (CRAG)", "Decision guide: which pattern for which problem"],
          desc: `ğŸš€ Advanced RAG patterns! Query transformation (HyDE), Self-RAG, context compression, CRAG. Decision guide included.

ğŸ“Œ Chapters: 0:00 Beyond Basics | 2:00 Query Transform | 6:00 HyDE | 9:00 Self-RAG | 12:00 CRAG | 15:00 Guide`,
          keywords: ["advanced RAG", "HyDE", "self-RAG", "query transformation", "CRAG"],
          visual: "Flowchart comparing 5 patterns. HyDE animation. Decision tree: which pattern to use."
        },
        cn: {
          title: "é«˜çº§RAGæ¨¡å¼ï¼šHyDEã€Self-RAGã€CRAG",
          outline: ["æ£€ç´¢å‰ï¼šæŸ¥è¯¢æ‰©å±•ã€åˆ†è§£ã€å›é€€æç¤º", "HyDEï¼šå‡è®¾æ–‡æ¡£åµŒå…¥", "Self-RAGï¼šå¤§æ¨¡å‹å†³å®šä½•æ—¶æ£€ç´¢", "æ£€ç´¢åï¼šä¸Šä¸‹æ–‡å‹ç¼©ã€ä¸­é—´é—å¤±é—®é¢˜", "çº æ­£RAGï¼ˆCRAGï¼‰", "å†³ç­–æŒ‡å—ï¼šå“ªç§æ¨¡å¼è§£å†³å“ªç§é—®é¢˜"],
          desc: `ğŸš€ é«˜çº§RAGæ¨¡å¼ï¼æŸ¥è¯¢æ”¹å†™ï¼ˆHyDEï¼‰ã€Self-RAGã€ä¸Šä¸‹æ–‡å‹ç¼©ã€CRAGã€‚åŒ…å«å†³ç­–æŒ‡å—ã€‚

ğŸ“Œ ç« èŠ‚ï¼š0:00 è¶…è¶ŠåŸºç¡€ | 2:00 æŸ¥è¯¢æ”¹å†™ | 6:00 HyDE | 9:00 Self-RAG | 12:00 CRAG | 15:00 æŒ‡å—`,
          keywords: ["é«˜çº§RAG", "HyDE", "Self-RAG", "æŸ¥è¯¢æ”¹å†™", "CRAGçº é”™"],
          visual: "5ç§æ¨¡å¼å¯¹æ¯”æµç¨‹å›¾ã€‚HyDEåŠ¨ç”»ã€‚å†³ç­–æ ‘ã€‚"
        }
      },
      {
        id: "10", time: "18-22 min", tags: ["project", "coding"],
        en: {
          title: "RAG with ElasticSearch / OpenSearch",
          outline: ["Why ElasticSearch for production", "Docker setup", "Inverted index + kNN in one system", "Hybrid search with ES", "Query understanding & intent detection", "Evaluation: MRR, NDCG, precision@k"],
          desc: `ğŸ”§ Production RAG with ElasticSearch! Docker, hybrid search, query understanding, MRR/NDCG evaluation.

ğŸ“Œ Chapters: 0:00 Why ES | 3:00 Docker | 7:00 Hybrid Search | 12:00 Query Understanding | 16:00 Eval`,
          keywords: ["ElasticSearch RAG", "OpenSearch", "production RAG", "MRR NDCG", "search engineering"],
          visual: "ES architecture: inverted + vector index. Docker Compose visual. Search metrics dashboard."
        },
        cn: {
          title: "ç”¨ElasticSearch/OpenSearchæ„å»ºç”Ÿäº§çº§æœç´¢",
          outline: ["ä¸ºä»€ä¹ˆç”Ÿäº§ç”¨ElasticSearch", "Dockeréƒ¨ç½²", "ä¸€ä¸ªç³»ç»Ÿæ”¯æŒå€’æ’+kNNå‘é‡æœç´¢", "ESæ··åˆæœç´¢å®ç°", "æŸ¥è¯¢ç†è§£ä¸æ„å›¾æ£€æµ‹", "è¯„ä¼°ï¼šMRRã€NDCGã€precision@k"],
          desc: `ğŸ”§ ESç”Ÿäº§çº§RAGï¼Dockeréƒ¨ç½²ã€æ··åˆæœç´¢ã€æŸ¥è¯¢ç†è§£ã€MRR/NDCGè¯„ä¼°ã€‚

ğŸ“Œ ç« èŠ‚ï¼š0:00 ä¸ºä»€ä¹ˆé€‰ES | 3:00 Docker | 7:00 æ··åˆæœç´¢ | 12:00 æŸ¥è¯¢ç†è§£ | 16:00 è¯„ä¼°`,
          keywords: ["ElasticSearchæ•™ç¨‹", "OpenSearch", "ç”Ÿäº§çº§RAG", "MRR NDCG", "æœç´¢å¼•æ“"],
          visual: "ESæ¶æ„å›¾ã€‚Docker Composeå¯è§†åŒ–ã€‚æœç´¢æŒ‡æ ‡ä»ªè¡¨ç›˜ã€‚"
        }
      }
    ]
  },
  {
    num: 4, color: "#fb7185", label: "PHASE 4",
    en: { title: "Cloud RAG â€” Multi-Cloud Deploy", sub: "3 videos Â· Cloud" },
    cn: { title: "äº‘ç«¯éƒ¨ç½² â€” å¤šäº‘å®æˆ˜", sub: "3 é›† Â· äº‘å¹³å°" },
    videos: [
      {
        id: "11", time: "18-22 min", tags: ["project", "coding"],
        en: {
          title: "RAG on AWS Bedrock: Knowledge Bases & Guardrails",
          outline: ["AWS Bedrock overview: managed LLM + RAG", "Knowledge Bases with S3 + OpenSearch Serverless", "Auto chunking, embedding, indexing", "Bedrock Guardrails for content safety", "Python boto3 for Bedrock RAG", "Cost: managed vs self-hosted"],
          desc: `â˜ï¸ RAG on AWS Bedrock! Knowledge Bases, OpenSearch Serverless, Guardrails. Enterprise RAG without managing infra.

ğŸ“Œ Chapters: 0:00 Overview | 3:00 KB Setup | 8:00 Guardrails | 12:00 Python SDK | 16:00 Cost`,
          keywords: ["AWS Bedrock RAG", "Bedrock Knowledge Bases", "Bedrock Guardrails", "managed RAG", "AWS AI"],
          visual: "AWS architecture: S3 â†’ KB â†’ OpenSearch â†’ Bedrock LLM. Console walkthrough. Cost comparison."
        },
        cn: {
          title: "AWS Bedrock RAGï¼šçŸ¥è¯†åº“ä¸å®‰å…¨æŠ¤æ ",
          outline: ["AWS Bedrockæ¦‚è§ˆï¼šæ‰˜ç®¡å¤§æ¨¡å‹+RAG", "çŸ¥è¯†åº“é…ç½®ï¼šS3 + OpenSearch Serverless", "è‡ªåŠ¨åˆ‡åˆ†ã€å‘é‡åŒ–ã€ç´¢å¼•", "Guardrailså†…å®¹å®‰å…¨æŠ¤æ ", "Python boto3æŸ¥è¯¢Bedrock", "æˆæœ¬ï¼šæ‰˜ç®¡vsè‡ªå»º"],
          desc: `â˜ï¸ AWS Bedrock RAGï¼çŸ¥è¯†åº“ã€OpenSearch Serverlessã€Guardrailsã€‚ä¼ä¸šçº§RAGæ— éœ€ç®¡ç†åŸºç¡€è®¾æ–½ã€‚

ğŸ“Œ ç« èŠ‚ï¼š0:00 æ¦‚è§ˆ | 3:00 çŸ¥è¯†åº“ | 8:00 å®‰å…¨æŠ¤æ  | 12:00 Python SDK | 16:00 æˆæœ¬`,
          keywords: ["AWS Bedrockæ•™ç¨‹", "BedrockçŸ¥è¯†åº“", "å®‰å…¨æŠ¤æ ", "æ‰˜ç®¡RAG", "AWS AIæœåŠ¡"],
          visual: "AWSæ¶æ„å›¾ã€‚æ§åˆ¶å°æ¼”ç¤ºã€‚æˆæœ¬å¯¹æ¯”è¡¨ã€‚"
        }
      },
      {
        id: "12", time: "15-18 min", tags: ["project", "coding"],
        en: {
          title: "RAG on GCP Vertex AI & Azure OpenAI",
          outline: ["GCP Vertex AI Search: grounding with enterprise data", "Gemini 2M context â€” is RAG still needed?", "Azure OpenAI + AI Search", "Multi-cloud abstraction with LiteLLM", "Three-cloud decision framework", "Cost optimization across clouds"],
          desc: `ğŸŒ RAG across 3 clouds! GCP Vertex AI, Azure OpenAI, AWS Bedrock comparison. Multi-cloud abstraction + decision framework.

ğŸ“Œ Chapters: 0:00 GCP | 5:00 Long Context vs RAG | 8:00 Azure | 12:00 Multi-Cloud | 15:00 Decision`,
          keywords: ["Vertex AI RAG", "Azure OpenAI RAG", "multi-cloud AI", "LiteLLM", "cloud AI comparison"],
          visual: "Three-column: AWS vs GCP vs Azure. Decision flowchart. Cost calculator."
        },
        cn: {
          title: "GCP Vertex AI ä¸ Azure OpenAI RAGå®æˆ˜",
          outline: ["GCP Vertex AI Searchï¼šä¼ä¸šæ•°æ®é”šå®š", "Gemini 2Mä¸Šä¸‹æ–‡â€”â€”è¿˜éœ€RAGå—ï¼Ÿ", "Azure OpenAI + AI Search", "å¤šäº‘æŠ½è±¡ï¼šLiteLLM", "ä¸‰äº‘å†³ç­–æ¡†æ¶", "è·¨äº‘æˆæœ¬ä¼˜åŒ–"],
          desc: `ğŸŒ ä¸‰å¤§äº‘RAGå¯¹æ¯”ï¼GCPã€Azureã€AWSå…¨é¢æ¯”è¾ƒã€‚å¤šäº‘æŠ½è±¡+å†³ç­–æ¡†æ¶ã€‚

ğŸ“Œ ç« èŠ‚ï¼š0:00 GCP | 5:00 é•¿ä¸Šä¸‹æ–‡vsRAG | 8:00 Azure | 12:00 å¤šäº‘ | 15:00 å†³ç­–`,
          keywords: ["Vertex AIæ•™ç¨‹", "Azure OpenAI RAG", "å¤šäº‘AI", "LiteLLM", "äº‘ç«¯RAGå¯¹æ¯”"],
          visual: "ä¸‰åˆ—å¯¹æ¯”ã€‚å†³ç­–æµç¨‹å›¾ã€‚æˆæœ¬è®¡ç®—å™¨ã€‚"
        }
      },
      {
        id: "13", time: "18-22 min", tags: ["project", "coding"],
        en: {
          title: "Multi-Agent RAG: Verification & Fact-Checking",
          outline: ["Multi-agent vs single-agent: when to go multi", "Architecture: retriever, verifier, synthesizer agents", "Document processing for complex docs", "Verification confidence scoring", "Building with LangGraph or CrewAI", "Use case: pitch deck verification"],
          desc: `ğŸ¤–ğŸ¤–ğŸ¤– Multi-agent RAG! Agents collaborate: retrieve â†’ verify â†’ synthesize. For high-stakes applications.

ğŸ“Œ Chapters: 0:00 Why Multi-Agent | 3:00 Architecture | 7:00 Implementation | 12:00 Scoring | 16:00 Demo`,
          keywords: ["multi-agent RAG", "LangGraph", "CrewAI", "AI agents", "fact checking AI"],
          visual: "Multi-agent orchestration diagram. Agent state machine. Demo with confidence scores."
        },
        cn: {
          title: "å¤šæ™ºèƒ½ä½“RAGï¼šéªŒè¯ä¸äº‹å®æ ¸æŸ¥",
          outline: ["å¤šæ™ºèƒ½ä½“vså•æ™ºèƒ½ä½“ï¼šä½•æ—¶ç”¨å¤šæ™ºèƒ½ä½“", "æ¶æ„ï¼šæ£€ç´¢ä»£ç†ã€éªŒè¯ä»£ç†ã€ç»¼åˆä»£ç†", "å¤æ‚æ–‡æ¡£å¤„ç†ç®¡é“", "éªŒè¯ç½®ä¿¡åº¦è¯„åˆ†", "ç”¨LangGraphæˆ–CrewAIæ„å»º", "æ¡ˆä¾‹ï¼šèèµ„ææ–™éªŒè¯"],
          desc: `ğŸ¤–ğŸ¤–ğŸ¤– å¤šæ™ºèƒ½ä½“RAGï¼ä»£ç†åä½œï¼šæ£€ç´¢â†’éªŒè¯â†’ç»¼åˆã€‚é€‚ç”¨äºé«˜è¦æ±‚åœºæ™¯ã€‚

ğŸ“Œ ç« èŠ‚ï¼š0:00 ä¸ºä»€ä¹ˆå¤šæ™ºèƒ½ä½“ | 3:00 æ¶æ„ | 7:00 å®ç° | 12:00 è¯„åˆ† | 16:00 æ¼”ç¤º`,
          keywords: ["å¤šæ™ºèƒ½ä½“RAG", "LangGraph", "CrewAI", "AIä»£ç†", "äº‹å®æ ¸æŸ¥"],
          visual: "å¤šæ™ºèƒ½ä½“ç¼–æ’å›¾ã€‚ä»£ç†çŠ¶æ€æœºã€‚æ¼”ç¤º+ç½®ä¿¡åº¦è¯„åˆ†ã€‚"
        }
      }
    ]
  },
  {
    num: 5, color: "#22d3ee", label: "PHASE 5",
    en: { title: "Interview Q&A", sub: "3 videos Â· Interview" },
    cn: { title: "é¢è¯•é¢˜æ”»ç•¥", sub: "3 é›† Â· é¢è¯•" },
    videos: [
      {
        id: "14", time: "15-18 min", tags: ["interview"],
        en: {
          title: "RAG Interview Questions: Fundamentals",
          outline: ["Q1: Explain RAG. When and how would you use it?", "Q2: Fine-tuning vs RAG vs prompt engineering?", "Q3: How do embeddings work? Compare models.", "Q4: Chunking strategies â€” how to choose?", "Q5: Compare vector databases.", "Each: model answer, common mistakes, follow-ups"],
          desc: `ğŸ¯ Ace your RAG interview! 5 fundamental questions with model answers, common mistakes, and follow-ups.

ğŸ“Œ Chapters: 0:00 How to Answer | 2:00 Q1 | 5:00 Q2 | 8:00 Q3 | 11:00 Q4 | 14:00 Q5
ğŸ”— Practice: https://ml-interview-prep-mu.vercel.app/topics/rag-retrieval`,
          keywords: ["RAG interview questions", "ML interview", "AI engineer interview", "RAG fundamentals"],
          visual: "Answer framework template cards. Good vs Bad answer comparison. Cheat sheet."
        },
        cn: {
          title: "RAGé¢è¯•é¢˜ç²¾è®²ï¼ˆä¸€ï¼‰ï¼šåŸºç¡€æ¦‚å¿µ",
          outline: ["Q1: è§£é‡ŠRAGã€‚ä»€ä¹ˆæ—¶å€™ã€å¦‚ä½•ä½¿ç”¨ï¼Ÿ", "Q2: å¾®è°ƒ vs RAG vs æç¤ºå·¥ç¨‹å¦‚ä½•é€‰ï¼Ÿ", "Q3: Embeddingå¦‚ä½•å·¥ä½œï¼Ÿæ¯”è¾ƒæ¨¡å‹ã€‚", "Q4: åˆ‡åˆ†ç­–ç•¥â€”â€”å¦‚ä½•é€‰æ‹©ï¼Ÿ", "Q5: å¯¹æ¯”å‘é‡æ•°æ®åº“ã€‚", "æ¯é¢˜ï¼šç­”é¢˜æ¡†æ¶ã€å¸¸è§é”™è¯¯ã€è¿½é—®"],
          desc: `ğŸ¯ RAGé¢è¯•é¢˜ç²¾è®²ï¼5é“åŸºç¡€é¢˜ï¼Œæ¯é¢˜æä¾›ç­”é¢˜æ¡†æ¶ã€å¸¸è§é”™è¯¯å’Œè¿½é—®æç¤ºã€‚

ğŸ“Œ ç« èŠ‚ï¼š0:00 æ€ä¹ˆç­” | 2:00 Q1 | 5:00 Q2 | 8:00 Q3 | 11:00 Q4 | 14:00 Q5
ğŸ”— ç»ƒä¹ ï¼šhttps://ml-interview-prep-mu.vercel.app/topics/rag-retrieval`,
          keywords: ["RAGé¢è¯•é¢˜", "æœºå™¨å­¦ä¹ é¢è¯•", "AIå·¥ç¨‹å¸ˆé¢è¯•", "RAGåŸºç¡€"],
          visual: "ç­”é¢˜æ¡†æ¶æ¨¡æ¿ã€‚å¥½ç­”æ¡ˆvsåç­”æ¡ˆå¯¹æ¯”ã€‚é€ŸæŸ¥å¡ã€‚"
        }
      },
      {
        id: "15", time: "15-18 min", tags: ["interview"],
        en: {
          title: "RAG Interview Questions: System Design",
          outline: ["Q6: Design RAG for 10M documents", "Q7: Evaluate & improve RAG in production?", "Q8: Explain hybrid search â€” when better?", "Q9: Multi-modal RAG (images + text)?", "Q10: Real-time data updates RAG?", "Template: requirements â†’ architecture â†’ tradeoffs"],
          desc: `ğŸ—ï¸ RAG system design interviews! 5 design questions with structured approach interviewers expect.

ğŸ“Œ Chapters: 0:00 Framework | 2:00 Q6 | 6:00 Q7 | 9:00 Q8 | 12:00 Q9 | 15:00 Q10`,
          keywords: ["RAG system design", "ML system design interview", "RAG at scale", "multi-modal RAG"],
          visual: "Whiteboard architectures. Scaling diagram. Tradeoff tables."
        },
        cn: {
          title: "RAGé¢è¯•é¢˜ç²¾è®²ï¼ˆäºŒï¼‰ï¼šç³»ç»Ÿè®¾è®¡",
          outline: ["Q6: ä¸º1000ä¸‡æ–‡æ¡£å…¬å¸è®¾è®¡RAG", "Q7: å¦‚ä½•è¯„ä¼°å’Œæ”¹è¿›ç”Ÿäº§RAGï¼Ÿ", "Q8: æ··åˆæœç´¢â€”â€”ä»€ä¹ˆæ—¶å€™æ›´å¥½ï¼Ÿ", "Q9: å¤šæ¨¡æ€RAGï¼ˆå›¾åƒ+æ–‡æœ¬ï¼‰ï¼Ÿ", "Q10: å®æ—¶æ•°æ®æ›´æ–°çš„RAGï¼Ÿ", "æ¨¡æ¿ï¼šéœ€æ±‚â†’æ¶æ„â†’æƒè¡¡"],
          desc: `ğŸ—ï¸ RAGç³»ç»Ÿè®¾è®¡é¢è¯•é¢˜ï¼5é“è®¾è®¡é¢˜ï¼Œç»“æ„åŒ–ç­”é¢˜æ–¹æ³•ã€‚

ğŸ“Œ ç« èŠ‚ï¼š0:00 æ¡†æ¶ | 2:00 Q6 | 6:00 Q7 | 9:00 Q8 | 12:00 Q9 | 15:00 Q10`,
          keywords: ["RAGç³»ç»Ÿè®¾è®¡", "ç³»ç»Ÿè®¾è®¡é¢è¯•", "å¤§è§„æ¨¡RAG", "å¤šæ¨¡æ€RAG"],
          visual: "ç™½æ¿æ¶æ„å›¾ã€‚æ‰©å±•è·¯å¾„å›¾ã€‚æƒè¡¡å¯¹æ¯”è¡¨ã€‚"
        }
      },
      {
        id: "16", time: "10-12 min", tags: ["interview", "concept"],
        en: {
          title: "RAG Cheat Sheet & Series Wrap-Up",
          outline: ["Complete RAG architecture cheat sheet", "Decision trees: chunking, vector DB, retrieval, cloud", "Top 10 RAG mistakes", "RAG in 2025+: agentic RAG, GraphRAG", "Resources: papers, tools, communities", "Series recap & what's next"],
          desc: `ğŸ“‹ Ultimate RAG cheat sheet! Architecture diagrams, decision trees, top 10 mistakes, 2025 trends. Pin this!

ğŸ“Œ Chapters: 0:00 Architecture | 3:00 Decision Trees | 5:00 Mistakes | 7:00 Trends | 9:00 Resources`,
          keywords: ["RAG cheat sheet", "RAG architecture", "GraphRAG", "agentic RAG", "RAG best practices"],
          visual: "One-page architecture poster. Decision tree flowcharts. Top 10 mistake cards. Future timeline."
        },
        cn: {
          title: "RAGé€ŸæŸ¥æ‰‹å†Œ & ç³»åˆ—æ€»ç»“",
          outline: ["å®Œæ•´RAGæ¶æ„é€ŸæŸ¥å›¾", "å†³ç­–æ ‘ï¼šåˆ‡åˆ†ã€å‘é‡DBã€æ£€ç´¢ã€äº‘", "åå¤§RAGå¸¸è§é”™è¯¯", "2025+ è¶‹åŠ¿ï¼šAgentic RAGã€GraphRAG", "èµ„æºï¼šè®ºæ–‡ã€å·¥å…·ã€ç¤¾åŒº", "ç³»åˆ—å›é¡¾å’Œä¸‹ä¸€æ­¥"],
          desc: `ğŸ“‹ RAGç»ˆæé€ŸæŸ¥æ‰‹å†Œï¼æ¶æ„å›¾ã€å†³ç­–æ ‘ã€åå¤§é”™è¯¯ã€2025è¶‹åŠ¿ã€‚æ”¶è—å¿…å¤‡ï¼

ğŸ“Œ ç« èŠ‚ï¼š0:00 æ¶æ„ | 3:00 å†³ç­–æ ‘ | 5:00 é”™è¯¯ | 7:00 è¶‹åŠ¿ | 9:00 èµ„æº`,
          keywords: ["RAGé€ŸæŸ¥", "RAGæ¶æ„", "GraphRAG", "Agentic RAG", "RAGæœ€ä½³å®è·µ"],
          visual: "ä¸€é¡µæ¶æ„æµ·æŠ¥ã€‚å†³ç­–æ ‘æµç¨‹å›¾ã€‚åå¤§é”™è¯¯å¡ç‰‡ã€‚æœªæ¥æ—¶é—´çº¿ã€‚"
        }
      }
    ]
  }
];

const tagStyles = {
  concept: { bg: "rgba(99,102,241,0.15)", color: "#818cf8" },
  coding: { bg: "rgba(34,211,238,0.15)", color: "#22d3ee" },
  project: { bg: "rgba(52,211,153,0.15)", color: "#34d399" },
  interview: { bg: "rgba(251,191,36,0.15)", color: "#fbbf24" },
};

function Tag({ label }) {
  const s = tagStyles[label] || { bg: "#1a1a26", color: "#8888a0" };
  return <span style={{ fontSize: 11, padding: "3px 8px", borderRadius: 4, fontFamily: "'JetBrains Mono', monospace", fontWeight: 500, background: s.bg, color: s.color }}>{label}</span>;
}

function VideoCard({ video, lang, defaultOpen }) {
  const [open, setOpen] = useState(defaultOpen || false);
  const d = video[lang];
  return (
    <div onClick={() => setOpen(!open)} style={{ background: "#12121a", border: "1px solid #2a2a3a", borderRadius: 12, cursor: "pointer", transition: "all 0.3s", ...(open ? { borderColor: "#6366f1", boxShadow: "0 4px 24px rgba(99,102,241,0.08)" } : {}) }}>
      <div style={{ display: "flex", alignItems: "flex-start", gap: 16, padding: "20px 24px" }}>
        <span style={{ fontFamily: "'Space Mono', monospace", fontSize: 12, fontWeight: 700, color: "#8888a0", background: "#1a1a26", padding: "6px 10px", borderRadius: 6, minWidth: 44, textAlign: "center", flexShrink: 0 }}>#{video.id}</span>
        <div style={{ flex: 1 }}>
          <div style={{ fontWeight: 600, fontSize: 16, color: "#e8e8f0" }}>{d.title}</div>
          <div style={{ display: "flex", gap: 12, marginTop: 8, flexWrap: "wrap" }}>
            {video.tags.map(t => <Tag key={t} label={t} />)}
            <span style={{ fontSize: 11, padding: "3px 8px", borderRadius: 4, fontFamily: "'JetBrains Mono', monospace", background: "#1a1a26", color: "#8888a0" }}>â± {video.time}</span>
          </div>
        </div>
        <span style={{ color: "#8888a0", fontSize: 18, transition: "transform 0.3s", transform: open ? "rotate(180deg)" : "rotate(0)", flexShrink: 0 }}>â–¼</span>
      </div>
      {open && (
        <div style={{ padding: "0 24px 24px", borderTop: "1px solid #2a2a3a" }}>
          <div style={{ marginTop: 16 }}>
            <div style={{ fontFamily: "'Space Mono', monospace", fontSize: 11, fontWeight: 700, color: "#818cf8", textTransform: "uppercase", letterSpacing: 1, marginBottom: 8 }}>{lang === "en" ? "Outline" : "å¤§çº²"}</div>
            <ul style={{ listStyle: "none", padding: 0 }}>
              {d.outline.map((item, i) => (
                <li key={i} style={{ position: "relative", paddingLeft: 20, marginBottom: 6, fontSize: 14, color: "#8888a0" }}>
                  <span style={{ position: "absolute", left: 0, color: "#6366f1", fontFamily: "'JetBrains Mono', monospace", fontSize: 12 }}>â†’</span>
                  {item}
                </li>
              ))}
            </ul>
          </div>
          <div style={{ marginTop: 16 }}>
            <div style={{ fontFamily: "'Space Mono', monospace", fontSize: 11, fontWeight: 700, color: "#818cf8", textTransform: "uppercase", letterSpacing: 1, marginBottom: 8 }}>YouTube Description</div>
            <div style={{ background: "#1a1a26", borderRadius: 8, padding: 16, fontSize: 13, color: "#8888a0", lineHeight: 1.7, borderLeft: "3px solid #6366f1", whiteSpace: "pre-line" }}>{d.desc}</div>
          </div>
          <div style={{ marginTop: 16 }}>
            <div style={{ fontFamily: "'Space Mono', monospace", fontSize: 11, fontWeight: 700, color: "#818cf8", textTransform: "uppercase", letterSpacing: 1, marginBottom: 8 }}>{lang === "en" ? "Keywords" : "å…³é”®å­—"}</div>
            <div style={{ display: "flex", gap: 6, flexWrap: "wrap" }}>
              {d.keywords.map((k, i) => <span key={i} style={{ fontSize: 11, padding: "2px 8px", background: "#1a1a26", border: "1px solid #2a2a3a", borderRadius: 4, color: "#8888a0", fontFamily: "'JetBrains Mono', monospace" }}>{k}</span>)}
            </div>
          </div>
          <div style={{ background: "rgba(34,211,238,0.05)", border: "1px solid rgba(34,211,238,0.15)", borderRadius: 8, padding: "12px 16px", fontSize: 13, color: "#22d3ee", marginTop: 12 }}>
            ğŸ¨ {d.visual}
          </div>
        </div>
      )}
    </div>
  );
}

export default function RAGSeriesPlan() {
  const [lang, setLang] = useState("en");
  const isCn = lang === "cn";

  return (
    <div style={{ background: "#0a0a0f", color: "#e8e8f0", fontFamily: "'DM Sans', sans-serif", minHeight: "100vh", lineHeight: 1.6 }}>
      <div style={{ maxWidth: 1200, margin: "0 auto", padding: "40px 24px" }}>

        {/* Language Toggle */}
        <div style={{ position: "sticky", top: 0, zIndex: 100, display: "flex", justifyContent: "flex-end", padding: "16px 0 8px", background: "linear-gradient(to bottom, #0a0a0f 70%, transparent)" }}>
          <div onClick={() => setLang(isCn ? "en" : "cn")} style={{ display: "flex", alignItems: "center", gap: 10, background: "#12121a", border: "1px solid #2a2a3a", borderRadius: 100, padding: "6px 10px", cursor: "pointer", userSelect: "none" }}>
            <span style={{ fontFamily: "'Space Mono', monospace", fontSize: 12, fontWeight: 700, color: isCn ? "#8888a0" : "#818cf8", padding: "0 4px", transition: "color 0.3s" }}>EN</span>
            <div style={{ width: 44, height: 24, background: "#1a1a26", border: "1px solid #2a2a3a", borderRadius: 100, position: "relative" }}>
              <div style={{ width: 18, height: 18, background: "#6366f1", borderRadius: "50%", position: "absolute", top: 2, left: 3, transition: "transform 0.3s cubic-bezier(0.4,0,0.2,1)", transform: isCn ? "translateX(20px)" : "translateX(0)", boxShadow: "0 2px 8px rgba(99,102,241,0.4)" }} />
            </div>
            <span style={{ fontFamily: "'Space Mono', monospace", fontSize: 12, fontWeight: 700, color: isCn ? "#818cf8" : "#8888a0", padding: "0 4px", transition: "color 0.3s" }}>ä¸­æ–‡</span>
          </div>
        </div>

        {/* Header */}
        <div style={{ textAlign: "center", marginBottom: 60, padding: "40px 0", position: "relative" }}>
          <div style={{ display: "inline-flex", alignItems: "center", gap: 8, background: "rgba(99,102,241,0.1)", border: "1px solid rgba(99,102,241,0.2)", borderRadius: 100, padding: "6px 16px", fontSize: 13, color: "#818cf8", fontWeight: 500, marginBottom: 24, fontFamily: "'Space Mono', monospace" }}>ğŸ“º LearnWithBeibei YouTube Series</div>
          <h1 style={{ fontFamily: "'Space Mono', monospace", fontSize: "clamp(32px, 5vw, 56px)", fontWeight: 700, lineHeight: 1.1, marginBottom: 16, background: "linear-gradient(135deg, #e8e8f0 30%, #6366f1 100%)", WebkitBackgroundClip: "text", WebkitTextFillColor: "transparent" }}>
            {isCn ? <>RAG ä»å…¥é—¨åˆ°ç²¾é€š<br />å®Œæ•´ç³»åˆ—æ•™ç¨‹</> : <>Complete RAG Tutorial<br />From Zero to Production</>}
          </h1>
          <p style={{ color: "#8888a0", fontSize: 18, maxWidth: 600, margin: "0 auto" }}>
            {isCn ? "å…¨é¢è¦†ç›–æ¦‚å¿µè®²è§£ã€å®æˆ˜é¡¹ç›®ã€ä»£ç æ¼”ç¤ºå’Œé¢è¯•é¢˜æ”»ç•¥çš„ç³»åˆ—æ•™ç¨‹" : "A comprehensive video series covering concepts, hands-on projects, coding, and interview Q&A"}
          </p>
          <div style={{ display: "flex", justifyContent: "center", gap: 32, marginTop: 32, flexWrap: "wrap" }}>
            {[{ n: "16", en: "Videos", cn: "è§†é¢‘" }, { n: "5", en: "Phases", cn: "é˜¶æ®µ" }, { n: "4", en: "Projects", cn: "é¡¹ç›®" }, { n: "~8hr", en: "Total", cn: "æ€»æ—¶é•¿" }].map(s => (
              <div key={s.en} style={{ textAlign: "center" }}>
                <div style={{ fontFamily: "'Space Mono', monospace", fontSize: 28, fontWeight: 700, color: "#818cf8" }}>{s.n}</div>
                <div style={{ fontSize: 12, color: "#8888a0", textTransform: "uppercase", letterSpacing: 1 }}>{isCn ? s.cn : s.en}</div>
              </div>
            ))}
          </div>
        </div>

        {/* Phases */}
        {PHASES.map(phase => (
          <div key={phase.num} style={{ marginBottom: 48 }}>
            <div style={{ display: "flex", alignItems: "center", gap: 16, marginBottom: 24, paddingBottom: 16, borderBottom: "1px solid #2a2a3a" }}>
              <span style={{ fontFamily: "'Space Mono', monospace", fontSize: 11, fontWeight: 700, color: phase.color === "#fbbf24" || phase.color === "#22d3ee" ? "#000" : "#0a0a0f", background: phase.color, padding: "4px 10px", borderRadius: 4, letterSpacing: 1 }}>{phase.label}</span>
              <span style={{ fontFamily: "'Space Mono', monospace", fontSize: 20, fontWeight: 700 }}>{isCn ? phase.cn.title : phase.en.title}</span>
              <span style={{ color: "#8888a0", fontSize: 14, marginLeft: "auto", whiteSpace: "nowrap" }}>{isCn ? phase.cn.sub : phase.en.sub}</span>
            </div>
            <div style={{ display: "flex", flexDirection: "column", gap: 16 }}>
              {phase.videos.map((v, i) => <VideoCard key={v.id} video={v} lang={lang} defaultOpen={phase.num === 1 && i === 0} />)}
            </div>
          </div>
        ))}

        {/* Footer */}
        <div style={{ textAlign: "center", padding: "40px 0", borderTop: "1px solid #2a2a3a", marginTop: 40, color: "#8888a0", fontSize: 13 }}>
          <p>{isCn ? "LearnWithBeibei Â· RAGæ•™ç¨‹ç³»åˆ— Â· 16é›† Â· å…±çº¦8å°æ—¶" : "LearnWithBeibei Â· RAG Tutorial Series Â· 16 Videos Â· ~8 Hours"}</p>
          <p style={{ marginTop: 8 }}>{isCn ? "æ¯é›†åŒ…å«ï¼šğŸ‡ºğŸ‡¸ è‹±æ–‡è„šæœ¬ Â· ğŸ‡¨ğŸ‡³ ä¸­æ–‡è„šæœ¬ Â· ğŸ¨ HTMLå¯è§†åŒ– Â· ğŸ“ æè¿°å’Œå…³é”®å­—" : "Each video: ğŸ‡ºğŸ‡¸ English script Â· ğŸ‡¨ğŸ‡³ Chinese script Â· ğŸ¨ HTML visual aid Â· ğŸ“ Description & Keywords"}</p>
        </div>
      </div>
    </div>
  );
}
